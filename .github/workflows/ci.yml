name: CI
on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  workflow_dispatch:
    inputs:
      image_tag:
        description: 'Optional extra image tag (e.g., v0.1.0)'
        required: false
        default: ''
concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true
env:
  IMAGE_NAME: ${{ secrets.DOCKERHUB_USERNAME }}/ids-unsw-api

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true
      - uses: actions/setup-python@v5
        with: { python-version: "3.11" }
      - run: python -m pip install --upgrade pip
      - run: pip install -r requirements.txt
      - name: Run tests
        run: pytest -q

# --- new job: DATA -----------------------------------------------------------
  data:
    runs-on: ubuntu-latest
    needs: [test]         # optional: run after unit/bundle tests
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - run: pip install -r requirements.txt
      - name: Create tiny raw dataset
        run: |
          python - <<'PY'
          import pandas as pd, numpy as np, pathlib
          out = pathlib.Path("artifacts/raw"); out.mkdir(parents=True, exist_ok=True)
          df = pd.DataFrame({
              "dur": np.linspace(0, 1, 16),
              "sbytes": np.arange(16),
              "label": (np.arange(16) % 2).astype(int),
          })
          df.to_csv(out/"raw.csv", index=False)
          print("Wrote", out/"raw.csv")
          PY
      - uses: actions/upload-artifact@v4
        with:
          name: raw
          path: artifacts/raw
# --- new job: FEATURES -------------------------------------------------------
  features:
    runs-on: ubuntu-latest
    needs: [data]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - run: pip install -r requirements.txt
      - uses: actions/download-artifact@v4
        with:
          name: raw
          path: work/raw
      - name: Build features
        run: |
          python - <<'PY'
          import pandas as pd, json, pathlib
          raw = pathlib.Path('work/raw/raw.csv')
          df  = pd.read_csv(raw)
          X   = pd.DataFrame({
              'x1': df['dur'],
              'x2': (df['sbytes'] / max(df['sbytes'].max(), 1)),
          })
          y   = df['label']
          out = pathlib.Path('artifacts/features'); out.mkdir(parents=True, exist_ok=True)
          X.to_csv(out/'X.csv', index=False)
          y.to_csv(out/'y.csv', index=False)
          (out/'feature_names.json').write_text(json.dumps({'features': list(X.columns)}))
          PY
      - uses: actions/upload-artifact@v4
        with:
          name: features
          path: artifacts/features
# --- new job: TRAIN ----------------------------------------------------------
  train:
    runs-on: ubuntu-latest
    needs: [features]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - run: pip install -r requirements.txt
      - uses: actions/download-artifact@v4
        with:
          name: features
          path: work/features
      - name: Train & log with MLflow
        run: |
          python - <<'PY'
          import pandas as pd, numpy as np, pathlib, json, mlflow, os, shutil
          X = pd.read_csv('work/features/X.csv').values
          y = pd.read_csv('work/features/y.csv').values.ravel()
          # tiny closed-form "model" using least squares
          X1 = np.c_[np.ones(len(X)), X]
          w, *_ = np.linalg.lstsq(X1, y, rcond=None)
          pred = X1 @ w
          rmse = float(np.sqrt(((pred - y)**2).mean()))
          mlflow.set_tracking_uri('file://' + str(pathlib.Path.cwd()/'mlruns'))
          mlflow.set_experiment('ci-demo')
          with mlflow.start_run(run_name='train-ci'):
              mlflow.log_metric('rmse', rmse)
              np.savez('model.npz', w=w)
              mlflow.log_artifact('model.npz', artifact_path='model')
              pathlib.Path('model').mkdir(exist_ok=True)
              (pathlib.Path('model')/'metrics.json').write_text(json.dumps({'rmse': rmse}))
          out = pathlib.Path('artifacts/train'); out.mkdir(parents=True, exist_ok=True)
          shutil.copytree('mlruns', out/'mlruns', dirs_exist_ok=True)
          print('RMSE:', rmse)
          PY
      - uses: actions/upload-artifact@v4
        with:
          name: mlruns
          path: artifacts/train/mlruns

  docker:
    runs-on: ubuntu-latest
    needs: [test, train]
    steps:
      - name: Checkout (with LFS for ONNX bundle)
        uses: actions/checkout@v4
        with:
          lfs: true
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      # Build a local tag we can run for tests
      - name: Build image (local test tag)
        run: |
          docker build -f Dockerfile.api -t ids-unsw-api:local .
      # Start the container and wait for it to be ready
      - name: Run container
        run: |
          docker run -d --name ids -p 8000:8000 ids-unsw-api:local
          # wait for /health
          for i in {1..30}; do
            curl -sf -H "Authorization: Bearer supersecret123" http://122.0.0.1:8000/health && break
            sleep 1
          done
      # Hit /features and /predict with a tiny payload
      - name: Exercise API
        run: |
          echo "== /health =="
          curl -s -H "Authorization: Bearer supersecret123" http://127.0.0.1:8000/health | jq .
          echo "== /features =="
          curl -s -H "Authorization: Bearer supersecret123" http://127.0.0.1:8000/features | jq .
          echo "== /predict =="
          curl -s -H "Authorization: Bearer supersecret123" \
               -H 'Content-Type: application/json' \
               -X POST \
               --data '{"instances":[{"dur":0,"proto":0,"service":0,"state":0,"spkts":0,"dpkts":0,"sbytes":0,"dbytes":0,"rate":0,"sload":0,"dload":0,"sloss":0,"dloss":0,"sinpkt":0,"dinpkt":0,"sjit":0,"djit":0,"swin":0,"stcpb":0,"dtcpb":0,"dwin":0,"tcprtt":0,"synack":0,"ackdat":0,"smean":0,"dmean":0,"trans_depth":0,"response_body_len":0,"ct_src_dport_ltm":0,"ct_dst_sport_ltm":0,"is_ftp_login":0,"ct_ftp_cmd":0,"ct_flw_http_mthd":0,"is_sm_ips_ports":0}]}' \
               http://127.0.0.1:8000/predict | jq .
      # Always stop the container so the job can finish cleanly
      - name: Stop container
        if: always()
        run: docker rm -f ids

      - name: Compute tags/labels
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.IMAGE_NAME }}
          tags: |
            # always
            type=raw,value=sha-${{ github.sha }}
            # main branch gets latest
            type=raw,value=latest,enable=${{ github.ref == 'refs/heads/main' }}
            # PRs get pr-<number>
            type=ref,event=pr
            # manual runs can add an extra tag
            type=raw,value=${{ github.event.inputs.image_tag }},enable=${{ github.event_name == 'workflow_dispatch' && github.event.inputs.image_tag != '' }}
      - name: Build & push release image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: Dockerfile.api
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

